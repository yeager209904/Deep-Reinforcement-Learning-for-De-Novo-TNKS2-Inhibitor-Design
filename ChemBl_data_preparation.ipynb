{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af74a327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 50000 molecules from ChEMBL...\n",
      "Downloaded 1000 molecules...\n",
      "Downloaded 2000 molecules...\n",
      "Downloaded 3000 molecules...\n",
      "Downloaded 4000 molecules...\n",
      "Downloaded 5000 molecules...\n",
      "Downloaded 6000 molecules...\n",
      "Downloaded 7000 molecules...\n",
      "Downloaded 8000 molecules...\n",
      "Downloaded 9000 molecules...\n",
      "Downloaded 10000 molecules...\n",
      "Downloaded 11000 molecules...\n",
      "Downloaded 12000 molecules...\n",
      "Downloaded 13000 molecules...\n",
      "Downloaded 14000 molecules...\n",
      "Downloaded 15000 molecules...\n",
      "Downloaded 16000 molecules...\n",
      "Downloaded 17000 molecules...\n",
      "Downloaded 18000 molecules...\n",
      "Downloaded 19000 molecules...\n",
      "Downloaded 20000 molecules...\n",
      "Downloaded 21000 molecules...\n",
      "Downloaded 22000 molecules...\n",
      "Downloaded 23000 molecules...\n",
      "Downloaded 24000 molecules...\n",
      "Downloaded 25000 molecules...\n",
      "Downloaded 26000 molecules...\n",
      "Downloaded 27000 molecules...\n",
      "Downloaded 28000 molecules...\n",
      "Downloaded 29000 molecules...\n",
      "Downloaded 30000 molecules...\n",
      "Downloaded 31000 molecules...\n",
      "Downloaded 32000 molecules...\n",
      "Downloaded 33000 molecules...\n",
      "Downloaded 34000 molecules...\n",
      "Downloaded 35000 molecules...\n",
      "Downloaded 36000 molecules...\n",
      "Downloaded 37000 molecules...\n",
      "Downloaded 38000 molecules...\n",
      "Downloaded 39000 molecules...\n",
      "Downloaded 40000 molecules...\n",
      "Downloaded 41000 molecules...\n",
      "Downloaded 42000 molecules...\n",
      "Downloaded 43000 molecules...\n",
      "Downloaded 44000 molecules...\n",
      "Downloaded 45000 molecules...\n",
      "Downloaded 46000 molecules...\n",
      "Downloaded 47000 molecules...\n",
      "Downloaded 48000 molecules...\n",
      "Downloaded 49000 molecules...\n",
      "Downloaded 50000 molecules...\n",
      "Filtering molecules for drug-likeness...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing molecules: 100%|██████████| 50000/50000 [00:43<00:00, 1154.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered from 50000 to 32785 molecules\n",
      "Saved SMILES files to ./data\n",
      "Training: 26228 molecules\n",
      "Validation: 3278 molecules\n",
      "Test: 3279 molecules\n",
      "Data preparation complete!\n",
      "You can now run transfer learning with:\n",
      "reinvent -l transfer_learning.log transfer_learning.toml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Data preparation script for REINVENT4 transfer learning\n",
    "Downloads and processes ChEMBL data for molecular generation\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, Crippen\n",
    "import sqlite3\n",
    "from typing import List, Optional\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ChEMBLDataProcessor:\n",
    "    def __init__(self, output_dir: str = \"./data\"):\n",
    "        self.output_dir = output_dir\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "    def download_chembl_subset(self, limit: int = 100000) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Download a subset of ChEMBL data via their web services API\n",
    "        For full dataset, you'd download the SQLite database\n",
    "        \"\"\"\n",
    "        print(f\"Downloading {limit} molecules from ChEMBL...\")\n",
    "        \n",
    "        # ChEMBL REST API endpoint for molecules\n",
    "        base_url = \"https://www.ebi.ac.uk/chembl/api/data/molecule\"\n",
    "        \n",
    "        molecules = []\n",
    "        offset = 0\n",
    "        batch_size = 1000\n",
    "        \n",
    "        while len(molecules) < limit:\n",
    "            params = {\n",
    "                'format': 'json',\n",
    "                'limit': batch_size,\n",
    "                'offset': offset,\n",
    "                'molecule_chembl_id__isnull': False,\n",
    "                'molecule_structures__canonical_smiles__isnull': False\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = requests.get(base_url, params=params, timeout=30)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "                \n",
    "                if not data.get('molecules'):\n",
    "                    break\n",
    "                    \n",
    "                for mol in data['molecules']:\n",
    "                    if mol.get('molecule_structures') and mol['molecule_structures'].get('canonical_smiles'):\n",
    "                        molecules.append({\n",
    "                            'chembl_id': mol['molecule_chembl_id'],\n",
    "                            'smiles': mol['molecule_structures']['canonical_smiles'],\n",
    "                            'molecular_weight': mol.get('molecule_properties', {}).get('mw_freebase'),\n",
    "                            'alogp': mol.get('molecule_properties', {}).get('alogp')\n",
    "                        })\n",
    "                        \n",
    "                        if len(molecules) >= limit:\n",
    "                            break\n",
    "                            \n",
    "                offset += batch_size\n",
    "                print(f\"Downloaded {len(molecules)} molecules...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading batch: {e}\")\n",
    "                break\n",
    "                \n",
    "        return pd.DataFrame(molecules)\n",
    "    \n",
    "    def filter_molecules(self, df: pd.DataFrame, \n",
    "                        min_mw: float = 150, \n",
    "                        max_mw: float = 500,\n",
    "                        min_atoms: int = 10,\n",
    "                        max_atoms: int = 50) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filter molecules based on drug-likeness criteria\n",
    "        \"\"\"\n",
    "        print(\"Filtering molecules for drug-likeness...\")\n",
    "        initial_count = len(df)\n",
    "        \n",
    "        valid_smiles = []\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing molecules\"):\n",
    "            smiles = row['smiles']\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            \n",
    "            if mol is None:\n",
    "                continue\n",
    "                \n",
    "            # Basic filters\n",
    "            mw = Descriptors.MolWt(mol)\n",
    "            num_atoms = mol.GetNumHeavyAtoms()\n",
    "            logp = Crippen.MolLogP(mol)\n",
    "            \n",
    "            # Apply filters\n",
    "            if (min_mw <= mw <= max_mw and \n",
    "                min_atoms <= num_atoms <= max_atoms and\n",
    "                -2 <= logp <= 5):  # Reasonable LogP range\n",
    "                \n",
    "                valid_smiles.append({\n",
    "                    'chembl_id': row['chembl_id'],\n",
    "                    'smiles': smiles,\n",
    "                    'molecular_weight': mw,\n",
    "                    'logp': logp,\n",
    "                    'num_atoms': num_atoms\n",
    "                })\n",
    "        \n",
    "        filtered_df = pd.DataFrame(valid_smiles)\n",
    "        print(f\"Filtered from {initial_count} to {len(filtered_df)} molecules\")\n",
    "        return filtered_df\n",
    "    \n",
    "    def split_data(self, df: pd.DataFrame, \n",
    "                   train_ratio: float = 0.8,\n",
    "                   val_ratio: float = 0.1) -> tuple:\n",
    "        \"\"\"\n",
    "        Split data into train/validation/test sets\n",
    "        \"\"\"\n",
    "        df = df.sample(frac=1).reset_index(drop=True)  # Shuffle\n",
    "        \n",
    "        n_train = int(len(df) * train_ratio)\n",
    "        n_val = int(len(df) * val_ratio)\n",
    "        \n",
    "        train_df = df[:n_train]\n",
    "        val_df = df[n_train:n_train + n_val]\n",
    "        test_df = df[n_train + n_val:]\n",
    "        \n",
    "        return train_df, val_df, test_df\n",
    "    \n",
    "    def save_smiles_files(self, train_df: pd.DataFrame, \n",
    "                         val_df: pd.DataFrame, \n",
    "                         test_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Save SMILES files in format expected by REINVENT4\n",
    "        \"\"\"\n",
    "        # Save training set\n",
    "        train_file = os.path.join(self.output_dir, \"chembl_molecules.smi\")\n",
    "        with open(train_file, 'w') as f:\n",
    "            for smiles in train_df['smiles']:\n",
    "                f.write(f\"{smiles}\\n\")\n",
    "        \n",
    "        # Save validation set\n",
    "        val_file = os.path.join(self.output_dir, \"chembl_validation.smi\")\n",
    "        with open(val_file, 'w') as f:\n",
    "            for smiles in val_df['smiles']:\n",
    "                f.write(f\"{smiles}\\n\")\n",
    "        \n",
    "        # Save test set\n",
    "        test_file = os.path.join(self.output_dir, \"chembl_test.smi\")\n",
    "        with open(test_file, 'w') as f:\n",
    "            for smiles in test_df['smiles']:\n",
    "                f.write(f\"{smiles}\\n\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata_file = os.path.join(self.output_dir, \"dataset_info.txt\")\n",
    "        with open(metadata_file, 'w') as f:\n",
    "            f.write(f\"Training molecules: {len(train_df)}\\n\")\n",
    "            f.write(f\"Validation molecules: {len(val_df)}\\n\")\n",
    "            f.write(f\"Test molecules: {len(test_df)}\\n\")\n",
    "            f.write(f\"Total molecules: {len(train_df) + len(val_df) + len(test_df)}\\n\")\n",
    "        \n",
    "        print(f\"Saved SMILES files to {self.output_dir}\")\n",
    "        print(f\"Training: {len(train_df)} molecules\")\n",
    "        print(f\"Validation: {len(val_df)} molecules\") \n",
    "        print(f\"Test: {len(test_df)} molecules\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main data preparation pipeline\n",
    "    \"\"\"\n",
    "    processor = ChEMBLDataProcessor()\n",
    "    \n",
    "    # Download ChEMBL subset\n",
    "    df = processor.download_chembl_subset(limit=50000)  # Adjust limit as needed\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"No molecules downloaded. Check your internet connection.\")\n",
    "        return\n",
    "    \n",
    "    # Filter for drug-like molecules\n",
    "    filtered_df = processor.filter_molecules(df)\n",
    "    \n",
    "    if filtered_df.empty:\n",
    "        print(\"No molecules passed filtering criteria.\")\n",
    "        return\n",
    "    \n",
    "    # Split data\n",
    "    train_df, val_df, test_df = processor.split_data(filtered_df)\n",
    "    \n",
    "    # Save SMILES files\n",
    "    processor.save_smiles_files(train_df, val_df, test_df)\n",
    "    \n",
    "    print(\"Data preparation complete!\")\n",
    "    print(\"You can now run transfer learning with:\")\n",
    "    print(\"reinvent -l transfer_learning.log transfer_learning.toml\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a49cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
